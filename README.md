# ğŸš€ Proyecto  Automation de Talento Tech

## ğŸ¯ PropÃ³sito del proyecto
Este proyecto tiene como objetivo **automatizar pruebas de UI y API** para el sitio **SauceDemo**, aplicando buenas prÃ¡cticas como:

- Page Object Model (POM)
- Manejo de datos externos (CSV / JSON)
- GeneraciÃ³n automÃ¡tica de reportes HTML
- Logging centralizado
- Captura automÃ¡tica de pantallas ante fallos

> âœ”ï¸ La estructura estÃ¡ diseÃ±ada para mantener orden, escalabilidad y facilidad de mantenimiento.

---

## ğŸ› ï¸ TecnologÃ­as utilizadas
- **Python 3.x**
- **Pytest** â†’ ejecuciÃ³n de pruebas
- **Selenium WebDriver** â†’ automatizaciÃ³n UI
- **jsonplaceholder** â†’ pruebas de API
- **Faker** â†’ generaciÃ³n de datos dinÃ¡micos
- **Logging**
- **CSV / JSON** para datos externos
- **GitHub Actions/CI** para una integracion continua y correr todas las pruebas cada vez que se hace un push

---

## ğŸ“Š Reportes y Logs

Durante la ejecuciÃ³n, el proyecto genera **tres tipos de resultados principales**:

### ğŸ“„ Reporte HTML
- Se genera automÃ¡ticamente como:  
  ```reporte.html```
- UbicaciÃ³n: **carpeta raÃ­z del proyecto**
- Incluye:
  - Tests ejecutados  
  - Estado (OK / FAIL)  
  - DuraciÃ³n  
  - Capturas de pantalla  

---

### ğŸ“ Logs de ejecuciÃ³n

Tambien se genera un log con informacion detallada de toda la ejecuciÃ³n de las pruebas en la siguiente ubicacion: ```logs/suite.log```

---

### ğŸ–¼ï¸ Capturas de pantalla
- Se generan **solo cuando una prueba falla**.  
- Permiten revisar visualmente el estado del navegador al momento del fallo.

---

## â–¶ï¸ Ejecutar todas las pruebas

Ejecuta la suite completa con:

```bash
python -m run_tests
```
Esto lanzarÃ¡ todos los tests y generarÃ¡ automÃ¡ticamente el reporte HTML, el log y las capturas.

## ğŸ“˜ Â¿CÃ³mo interpretar los reportes?

Al ejecutar run_test.py, se genera un archivo HTML con:

âœ”ï¸ Lista completa de pruebas

âœ”ï¸ Estado de cada prueba

âœ”ï¸ DuraciÃ³n

âœ”ï¸ Screenshots en pruebas fallidas

Este reporte permite analizar rÃ¡pidamente resultados y detectar errores.

## ğŸ§ª Pruebas incluidas
ğŸ” Login

Login exitoso

Login fallido

Login con datos generados con Faker

ğŸ“¦ Inventario

ValidaciÃ³n de productos en pantalla

Comportamiento al agregar items

ğŸ›’ Carrito

Agregar y eliminar productos

Validaciones de estado

ğŸŒ API (JsonPlaceHolder)

GET users

POST create user

DELETE user

ValidaciÃ³n de cÃ³digos HTTP

ValidaciÃ³n de estructura JSON

## ğŸ“‚ Manejo de datos de prueba

En la carpeta datos/ se incluyen archivos externos como:

data_login.csv â†’ usuarios vÃ¡lidos e invÃ¡lidos

productos.json â†’ datos de productos para la UI

Esto permite separar la lÃ³gica del cÃ³digo de los datos, facilitando configuraciones y escalabilidad.

## ğŸ§¾ ConclusiÃ³n

Este proyecto ofrece una arquitectura limpia, modular y escalable para automatizar pruebas con Python y Pytest.

Incluye:

EjecuciÃ³n centralizada con run_test.py

Reporte HTML automÃ¡tico

Registro completo en logs

Buena organizaciÃ³n de carpetas y datos

Permite agregar nuevos tests de forma simple sin alterar el nÃºcleo del framework, garantizando buenas prÃ¡cticas y extensibilidad en el tiempo.

Permite correr todas las pruebas cada vez que se hace una actualiza y asi detectar cualquiero posible error en el menor tiempo posible